#!/bin/bash
# Script to switch between different models easily

echo "Available models:"
echo "1. Qwen/Qwen3-30B-A3B-Instruct-2507-FP8 (default, 30.5B total/3.3B active, FP8)"
echo "2. Qwen/Qwen1.5-MoE-A2.7B (14.3B total/2.7B active params)"
echo "3. EleutherAI/gpt-j-6b (6B params)"
echo "4. bigscience/bloom-7b1 (7B params)"
echo ""

read -p "Select model (1-4) or enter custom model name: " choice

case $choice in
    1)
        MODEL="Qwen/Qwen3-30B-A3B-Instruct-2507-FP8"
        ;;
    2)
        MODEL="Qwen/Qwen1.5-MoE-A2.7B"
        ;;
    3)
        MODEL="EleutherAI/gpt-j-6b"
        ;;
    4)
        MODEL="bigscience/bloom-7b1"
        ;;
    *)
        MODEL="$choice"
        ;;
esac

echo ""
echo "Switching to model: $MODEL"

# Update .env.model
cat > .env.model << EOF
# Model Configuration
# Generated by switch_model.sh at $(date)

MODEL_NAME=$MODEL
MODEL_PRECISION=fp16
EOF

# Update config/model_config.py
cat > config/model_config.py << 'EOF'
"""
Central model configuration for the DNAI project.
Change the model here to update it across the entire project.
"""

# Primary model configuration
DEFAULT_MODEL_NAME = "MODEL_PLACEHOLDER"
DEFAULT_MODEL_ARCHITECTURE = "mixture-of-experts"
DEFAULT_MODEL_LAYERS = 28  # Default, will be overridden per model
DEFAULT_MODEL_EXPERTS = 16
DEFAULT_MODEL_ACTIVE_PARAMS = "2.7B"  # Default
DEFAULT_MODEL_TOTAL_PARAMS = "14.3B"  # Default

# Fallback models for testing
FALLBACK_MODELS = [
    "EleutherAI/gpt-j-6b",
    "bigscience/bloom-7b1",
]

# Model-specific settings
MODEL_CONFIGS = {
    "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8": {
        "architecture": "mixture-of-experts",
        "num_layers": 48,
        "num_experts": 128,
        "activated_experts": 8,
        "active_params": "3.3B",
        "total_params": "30.5B",
        "precision": "fp8",
        "max_sequence_length": 262144,
        "requires_transformers": ">=4.51.0",
    },
    "Qwen/Qwen1.5-MoE-A2.7B": {
        "architecture": "mixture-of-experts",
        "num_layers": 28,
        "num_experts": 16,
        "active_params": "2.7B",
        "total_params": "14.3B",
        "precision": "fp16",
        "max_sequence_length": 32768,
    },
    "openai/gpt-oss-20b": {
        "architecture": "gpt-neox",
        "num_layers": 24,
        "num_experts": 16,
        "active_params": "20B",
        "total_params": "20B",
        "precision": "fp16",
        "max_sequence_length": 2048,
    },
    "EleutherAI/gpt-j-6b": {
        "architecture": "gpt-j",
        "num_layers": 28,
        "num_experts": 1,
        "active_params": "6B",
        "total_params": "6B",
        "precision": "fp16",
        "max_sequence_length": 2048,
    },
    "bigscience/bloom-7b1": {
        "architecture": "bloom",
        "num_layers": 30,
        "num_experts": 1,
        "active_params": "7.1B",
        "total_params": "7.1B",
        "precision": "fp16",
        "max_sequence_length": 2048,
    },
}

def get_model_config(model_name: str = None):
    """Get configuration for a specific model."""
    if model_name is None:
        model_name = DEFAULT_MODEL_NAME
    
    if model_name in MODEL_CONFIGS:
        return MODEL_CONFIGS[model_name]
    
    # Return default config for unknown models
    return {
        "architecture": "unknown",
        "num_layers": 24,
        "num_experts": 1,
        "active_params": "unknown",
        "total_params": "unknown",
        "precision": "fp16",
        "max_sequence_length": 2048,
    }
EOF

# Replace placeholder with actual model
sed -i.bak "s|MODEL_PLACEHOLDER|$MODEL|g" config/model_config.py
rm -f config/model_config.py.bak

echo "âœ… Model configuration updated"
echo ""
echo "To apply changes:"
echo "1. Clear cache: ./clear_cache.sh"
echo "2. Restart GPU node: systemctl restart dnai"
echo ""
echo "Or set temporarily: export MODEL_NAME=$MODEL"