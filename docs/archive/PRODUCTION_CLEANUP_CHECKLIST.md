# Production Cleanup Checklist

> ğŸš¨ **í”„ë¡œë•ì…˜ ë°°í¬ ì „ í•„ìˆ˜ ì •ë¦¬ ì‚¬í•­**
> 
> ì´ íŒŒì¼ì˜ ëª¨ë“  í•­ëª©ì„ í™•ì¸í•˜ê³  ì •ë¦¬í•œ í›„ í”„ë¡œë•ì…˜ì— ë°°í¬í•˜ì„¸ìš”.
> ê¸°ëŠ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” í…ŒìŠ¤íŠ¸/ì„ì‹œ ì½”ë“œë§Œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## âŒ ì‚­ì œí•  íŒŒì¼ë“¤ (ì „ì²´ ì‚­ì œ ê°€ëŠ¥)

### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë“¤
- [x] `scripts/test_concurrent_inference.py` - Phase 1 í…ŒìŠ¤íŠ¸ âœ… ì‚­ì œë¨
- [x] `scripts/test_micro_step_learning.py` - Phase 2 í…ŒìŠ¤íŠ¸ âœ… ì‚­ì œë¨
- [x] `scripts/test_dual_model_streams.py` - Phase 3 í…ŒìŠ¤íŠ¸ âœ… ì‚­ì œë¨
- [x] `scripts/test_complete_system.py` - ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ âœ… ì‚­ì œë¨

## ğŸ”§ íŒŒì¼ ë‚´ ì •ë¦¬í•  ì½”ë“œë“¤

### backend/learning/micro_step_trainer.py
- [x] **ë¼ì¸ 465-500**: `async def demo_micro_step_training()` í•¨ìˆ˜ ì „ì²´ âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 500-520**: `if __name__ == "__main__":` ë¸”ë¡ âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 430-460**: `DummyDataset` í´ë˜ìŠ¤ (demoìš©) âœ… ì‚­ì œë¨

### backend/learning/dual_model_manager.py
- [x] **ë¼ì¸ 380-450**: `async def demo_dual_model()` í•¨ìˆ˜ ì „ì²´ âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 320-380**: `class SimpleModel(nn.Module)` (demoìš©) âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 450-460**: `if __name__ == "__main__":` ë¸”ë¡ âœ… ì‚­ì œë¨

### backend/inference/batch_manager.py
- [x] **ë¼ì¸ 430-490**: `async def demo_batch_manager()` í•¨ìˆ˜ ì „ì²´ âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 400-430**: `class MockModel` (demoìš©) âœ… ì‚­ì œë¨
- [x] **ë¼ì¸ 490-500**: `if __name__ == "__main__":` ë¸”ë¡ âœ… ì‚­ì œë¨

### backend/p2p/concurrent_inference.py
- [x] **ë¼ì¸ 580-620**: `async def demo_concurrent_system()` í•¨ìˆ˜ (ì—†ìŒ) âœ… í•´ë‹¹ ì—†ìŒ
- [x] **í•˜ë“œì½”ë”©ëœ Mock ë°ì´í„°**: âœ… ì„¤ì • ê°€ëŠ¥í•˜ë„ë¡ ê°œì„ ë¨
  - [x] ë¼ì¸ 340-345: `torch.randn(4, 512)` â†’ payloadì—ì„œ ì„¤ì • ê°€ëŠ¥ âœ… ì™„ë£Œ
  - [x] ë¼ì¸ 430-435: `torch.randn(1, 512)` â†’ input_shape íŒŒë¼ë¯¸í„° ì¶”ê°€ âœ… ì™„ë£Œ
  - [x] ë¼ì¸ 310-315: `nn.Linear(512, 512)` â†’ ì‹¤ì œ ëª¨ë¸ ìš°ì„  ì‚¬ìš© âœ… ì™„ë£Œ

## ğŸ› Debug/Print ë¬¸ ì •ë¦¬

### ì „ì²´ íŒŒì¼ì—ì„œ ì°¾ì•„ì„œ ì •ë¦¬í•  ê²ƒë“¤
```bash
# ê²€ìƒ‰ ëª…ë ¹ì–´ë¡œ ì°¾ê¸°
grep -r "print.*DEBUG" backend/
grep -r "print.*âœ…\|âŒ\|ğŸš€\|ğŸ“Š" backend/
```

- [x] **backend/p2p/distributed_inference.py**: âœ… loggerë¡œ ë³€ê²½ë¨
  - [x] `print(f"DEBUG: ExpertNodeServer init - node_id: {node_id}, port: {port}")` â†’ logger.info
  
- [x] **backend/learning/micro_step_trainer.py**: âœ… demo ì½”ë“œì™€ í•¨ê»˜ ì‚­ì œë¨
  - [x] `print("âœ… Learning preempted successfully")` â†’ ì‚­ì œë¨
  - [x] `print("âœ… Meta chain initialized with MoE architecture.")` â†’ ì‚­ì œë¨
  
- [x] **backend/inference/batch_manager.py**: âœ… demo ì½”ë“œì™€ í•¨ê»˜ ì‚­ì œë¨
  - [x] `print("ğŸš€ Batch Manager Demo")` â†’ ì‚­ì œë¨
  - [x] `print("=" * 50)` (ë°ëª¨ ê´€ë ¨) â†’ ì‚­ì œë¨

## ğŸ”„ êµì²´í•  í•˜ë“œì½”ë”© ì„¤ì •ë“¤

### backend/p2p/concurrent_inference.py
- [ ] **ë¼ì¸ 330-340**: ë”ë¯¸ ëª¨ë¸ ì´ˆê¸°í™” â†’ ì‹¤ì œ MoE ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ êµì²´
```python
# ì‚­ì œí•  ì½”ë“œ:
model = nn.Linear(512, 512)
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# êµì²´í•  ì½”ë“œ:
# ì‹¤ì œ MoE ëª¨ë¸ ë¡œë”© ë¡œì§
```

### backend/learning/dual_model_manager.py
- [ ] **ë¼ì¸ 45-55**: í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ â†’ ì‹¤ì œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¡œ êµì²´

## ğŸ¯ ë¡œê¹… ë ˆë²¨ ì¡°ì •

### Debug â†’ Info ë ˆë²¨ë¡œ ë³€ê²½
- [ ] `logger.debug()` â†’ `logger.info()` (ì¤‘ìš”í•œ ê²ƒë“¤)
- [ ] ë¶ˆí•„ìš”í•œ `logger.debug()` ì œê±°

### ìœ ì§€í•  ë¡œê¹… (ì‚­ì œ ê¸ˆì§€)
- âœ… `logger.info("ì‹œìŠ¤í…œ ì‹œì‘/ì¢…ë£Œ ë©”ì‹œì§€")`
- âœ… `logger.error("ì—ëŸ¬ ì²˜ë¦¬ ë©”ì‹œì§€")`
- âœ… `logger.warning("ê²½ê³  ë©”ì‹œì§€")`

## ğŸ“‹ ì •ë¦¬ ì‘ì—… ìˆœì„œ

### 1ë‹¨ê³„: í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ
```bash
rm scripts/test_*.py
```

### 2ë‹¨ê³„: Demo ì½”ë“œ ì •ë¦¬
ê° íŒŒì¼ì—ì„œ `demo_*` í•¨ìˆ˜ë“¤ê³¼ `if __name__ == "__main__":` ë¸”ë¡ ì‚­ì œ

### 3ë‹¨ê³„: Mock ë°ì´í„° êµì²´
í•˜ë“œì½”ë”©ëœ `torch.randn()` ë“±ì„ ì‹¤ì œ ë°ì´í„° ì†ŒìŠ¤ë¡œ êµì²´

### 4ë‹¨ê³„: Debug Print ì •ë¦¬
ì´ëª¨ì§€ê°€ í¬í•¨ëœ printë¬¸ë“¤ì„ ì ì ˆí•œ ë¡œê¹…ìœ¼ë¡œ êµì²´

### 5ë‹¨ê³„: ìµœì¢… ê²€ì¦
```bash
# ë‚¨ì€ í…ŒìŠ¤íŠ¸ ì½”ë“œ í™•ì¸
grep -r "demo\|test\|mock" backend/ --exclude-dir=__pycache__

# í•˜ë“œì½”ë”© í™•ì¸  
grep -r "torch.randn\|nn.Linear.*512" backend/

# Debug print í™•ì¸
grep -r "print.*ğŸš€\|âœ…\|âŒ" backend/
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ì ˆëŒ€ ì‚­ì œí•˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒë“¤
- âŒ í´ë˜ìŠ¤ ì •ì˜ë“¤ (`InferenceQueue`, `MicroStepTrainer`, etc.)
- âŒ API ì—”ë“œí¬ì¸íŠ¸ í•¸ë“¤ëŸ¬ë“¤
- âŒ ì„¤ì • í´ë˜ìŠ¤ë“¤ (`*Config`)
- âŒ `get_status()` ë©”ì„œë“œë“¤
- âŒ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì½”ë“œë“¤
- âŒ ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ë“¤

### ê²€ì¦ ë°©ë²•
ê° ë‹¨ê³„ í›„ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:
```bash
# ê¸°ë³¸ ì„œë²„ ì‹œì‘ í…ŒìŠ¤íŠ¸
./server.sh start api

# API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸  
curl -X POST "http://127.0.0.1:8000/chat" -H "Content-Type: application/json" \
  -d '{"prompt": "test", "use_moe": true}'
```

---

**âœ… ëª¨ë“  í•­ëª© ì²´í¬ ì™„ë£Œ ì‹œ í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ**